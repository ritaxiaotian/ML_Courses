# 1. Udemy The Ultimate Hands-On Hadoop - Tame your Big Data! 

https://www.udemy.com/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/v4/overview

### Section 1 Learn all the buzzwords and install hadoop

#### 1.1 Introduction and install hadoop on your desktop

1. Install VirtualBox

Ubuntu 16.04 ("Xenial")  i386 |  AMD64

i386 refers to the 32-bit edition and amd64 (or x86_64) refers to the 64-bit edition for Intel and AMD processors. 

2. hortonworks.com/sandbox

3. Import Hortonworks Docker Sandbox into VM -- It's a pre-installed Hadoop environment

4. download movie data from https://grouplens.org/

5. run Docker Sandbox: maria_dev; maria_dev

http://127.0.0.1:8888/#

6. Use Hive to operate on u.data & u.item

**Not really on a relational database. The tool Hive let us interact with our data on Hadoop as if it were a relational database.**


#### 1.2 Hadoop overview and history


#### 1.3 overview of the Hadoop Ecosystem


#### 1.4 Tips for using this course

### Section 2 Using Hadoop's Core: HDFS and MapReduce

#### 5 HDFS: What it is, and how it works

#### 6. Install the MovieLens dataset into HDFS using the command line

#### 7. MapReduce:what it is and how it works

#### 8. How MapReduce distributes processing

#### 9. MapReduce example: Break down movie ratings by rating score

#### 10. Troubleshooding tips: installing pip and mrjob

#### 11. 

# 2. Udemy Spark and Python for Big Data with PySpark

https://www.udemy.com/spark-and-python-for-big-data-with-pyspark/learn/v4/overview
